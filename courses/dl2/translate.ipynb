{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French/English parallel texts from http://www.statmt.org/wmt15/translation-task.html . It was created by Chris Callison-Burch, who crawled millions of web pages and then used *a set of simple heuristics to transform French URLs onto English URLs (i.e. replacing \"fr\" with \"en\" and about 40 other hand-written rules), and assume that these documents are translations of each other*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data\n"
     ]
    }
   ],
   "source": [
    "%cd data\n",
    "%mkdir translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~20 minutes to download at 1.5 MB/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#48abf9 32KiB/2.4GiB(0%) CN:5 DL:\u001b[32m73KiB\u001b[0m ETA:\u001b[33m9h34m4s\u001b[0m]\u001b[0m     \n",
      "07/02 05:11:30 [\u001b[1;31mERROR\u001b[0m] CUID#10 - Download aborted. URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "Exception: [AbstractCommand.cc:350] errorCode=29 URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "  -> [HttpSkipResponseCommand.cc:224] errorCode=29 The response status is not successful. status=503\n",
      "\n",
      "07/02 05:11:30 [\u001b[1;31mERROR\u001b[0m] CUID#8 - Download aborted. URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "Exception: [AbstractCommand.cc:350] errorCode=29 URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "  -> [HttpSkipResponseCommand.cc:224] errorCode=29 The response status is not successful. status=503\n",
      "\n",
      "07/02 05:11:30 [\u001b[1;31mERROR\u001b[0m] CUID#7 - Download aborted. URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "Exception: [AbstractCommand.cc:350] errorCode=29 URI=http://www.statmt.org/wmt10/training-giga-fren.tar\n",
      "  -> [HttpSkipResponseCommand.cc:224] errorCode=29 The response status is not successful. status=503\n",
      " *** Download Progress Summary as of Mon Jul  2 05:12:30 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 95MiB/2.4GiB(3%) CN:2 DL:1.6MiB ETA:24m43s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:13:30 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 206MiB/2.4GiB(8%) CN:2 DL:1.9MiB ETA:19m40s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:14:31 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 322MiB/2.4GiB(13%) CN:2 DL:1.9MiB ETA:18m41s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:15:31 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 439MiB/2.4GiB(17%) CN:2 DL:1.9MiB ETA:17m40s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:16:32 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 576MiB/2.4GiB(23%) CN:2 DL:2.3MiB ETA:13m14s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:17:32 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 721MiB/2.4GiB(29%) CN:2 DL:2.3MiB ETA:12m12s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:18:33 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 866MiB/2.4GiB(34%) CN:2 DL:2.3MiB ETA:11m13s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:19:34 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 0.9GiB/2.4GiB(40%) CN:2 DL:2.3MiB ETA:10m12s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:20:34 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.1GiB/2.4GiB(46%) CN:2 DL:2.3MiB ETA:9m11s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:21:35 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.2GiB/2.4GiB(50%) CN:2 DL:1.2MiB ETA:15m59s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:22:35 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.2GiB/2.4GiB(53%) CN:2 DL:1.0MiB ETA:17m51s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:23:36 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.3GiB/2.4GiB(55%) CN:2 DL:917KiB ETA:20m17s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:24:37 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.4GiB/2.4GiB(58%) CN:2 DL:901KiB ETA:19m38s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:25:37 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.4GiB/2.4GiB(60%) CN:2 DL:901KiB ETA:18m38s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:26:38 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.5GiB/2.4GiB(62%) CN:2 DL:1.3MiB ETA:11m23s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:27:39 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.5GiB/2.4GiB(66%) CN:2 DL:1.3MiB ETA:10m7s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:28:40 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.6GiB/2.4GiB(70%) CN:2 DL:1.9MiB ETA:6m24s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:29:40 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.8GiB/2.4GiB(74%) CN:2 DL:1.9MiB ETA:5m24s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:30:41 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 1.9GiB/2.4GiB(79%) CN:2 DL:1.9MiB ETA:4m23s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:31:41 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 2.0GiB/2.4GiB(84%) CN:2 DL:1.8MiB ETA:3m29s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:32:42 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 2.1GiB/2.4GiB(88%) CN:2 DL:1.6MiB ETA:3m3s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Download Progress Summary as of Mon Jul  2 05:33:42 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 2.2GiB/2.4GiB(92%) CN:2 DL:1.6MiB ETA:2m3s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:34:43 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 2.3GiB/2.4GiB(95%) CN:2 DL:1.5MiB ETA:1m5s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 05:35:44 2018 ***              \n",
      "===============================================================================\n",
      "[#48abf9 2.4GiB/2.4GiB(99%) CN:2 DL:1.7MiB ETA:1s]\n",
      "FILE: /home/ubuntu/data/training-giga-fren.tar\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#48abf9 2.4GiB/2.4GiB(99%) CN:2 DL:\u001b[32m1.7MiB\u001b[0m]\u001b[0m                       \n",
      "07/02 05:35:45 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /home/ubuntu/data/training-giga-fren.tar\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "48abf9|\u001b[1;32mOK\u001b[0m  |   1.7MiB/s|/home/ubuntu/data/training-giga-fren.tar\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "!aria2c --file-allocation=none -c -x 5 -s 5 http://www.statmt.org/wmt10/training-giga-fren.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf training-giga-fren.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mv giga-fren.release2.fixed.en.gz giga-fren.release2.fixed.fr.gz training-giga-fren.tar translate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/translate\n"
     ]
    }
   ],
   "source": [
    "%cd translate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: This does not look like a tar archive\n",
      "tar: Skipping to next header\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "# Strange error\n",
    "!tar -xzf giga-fren.release2.fixed.en.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve the previous issue\n",
    "!gunzip giga-fren.release2.fixed.en.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip giga-fren.release2.fixed.fr.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup the directories and files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH / 'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname = 'giga-fren.release2.fixed'\n",
    "en_fname = PATH / f'{fname}.en'\n",
    "fr_fname = PATH / f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural model takes a long time\n",
    "\n",
    "- Google's model has 8 layers\n",
    "- we are going to build a simpler one\n",
    "- Instead of a general model we will translate French questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question regex search filters\n",
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "# grabbing lines from the English and French source texts\n",
    "lines = ( (re_eq.search(eq), re_fq.search(fq))\n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "# isolate the questions\n",
    "qs = [(e.group(), f.group()) for e, f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the questions for later\n",
    "pickle.dump(qs, (PATH / 'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in pickled questions\n",
    "qs = pickle.load((PATH / 'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52331\n",
      "[('What is light ?', 'Qu’est-ce que la lumière?'), ('Who are we?', 'Où sommes-nous?'), ('Where did we come from?', \"D'où venons-nous?\"), ('What would we do without it?', 'Que ferions-nous sans elle ?'), ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?', 'Quelle sont les coordonnées (latitude et longitude) de Badger, à Terre-Neuve-etLabrador?')]\n"
     ]
    }
   ],
   "source": [
    "# ======================================== START DEBUG ========================================\n",
    "print(len(qs))\n",
    "print(qs[:5])\n",
    "# ======================================== END DEBUG ========================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', 3), ('y', 4), ('z', 5)]\n",
      "('x', 'y', 'z')\n",
      "(3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "# ======================================== START DEBUG ========================================\n",
    "# Python zip method: https://www.programiz.com/python-programming/methods/built-in/zip\n",
    "# What is iterable, iterator: https://stackoverflow.com/questions/9884132/what-exactly-are-iterator-iterable-and-iteration\n",
    "coord = ['x', 'y', 'z']\n",
    "value = [3, 4, 5, 0, 9]\n",
    "result = zip(coord, value)\n",
    "result_list = list(result)\n",
    "print(result_list)\n",
    "# unzip result_list\n",
    "c, v = zip(*result_list)\n",
    "print(c)\n",
    "print(v)\n",
    "# ======================================== END DEBUG ========================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize all the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs, fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: tokenizing for French is much different compared to english_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz (39.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 39.8MB 71.0MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
      "  Running setup.py install for fr-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fr-core-news-sm-2.0.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/fr_core_news_sm\n",
      "    -->\n",
      "    /home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download spaCy 'fr' model.Otherwise, you'll encounter errorr \"OSError: [E050] Can't find model 'fr'...\"\n",
    "!python -m spacy download fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['what', 'is', 'light', '?'],\n",
       "  ['who', 'are', 'we', '?'],\n",
       "  ['where', 'did', 'we', 'come', 'from', '?']],\n",
       " [['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?'],\n",
       "  ['où', 'sommes', '-', 'nous', '?'],\n",
       "  [\"d'\", 'où', 'venons', '-', 'nous', '?']])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tok[:3], fr_tok[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check stats for the sentences length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 28.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90th percentile of English and French sentences length.\n",
    "np.percentile([len(o) for o in en_tok], 90), np.percentile([len(o) for o in fr_tok], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are keeping tokens that are less than 30 chars. The filter is applied on the English words, and the same tokens are kept for French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o) < 30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our work\n",
    "pickle.dump(en_tok, (PATH / 'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH / 'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toks2ids(tok, pre):\n",
    "    \"\"\"\n",
    "    Numericalize words to integers.\n",
    "    \n",
    "    Arguments:\n",
    "        tok: token\n",
    "        pre: prefix\n",
    "    \"\"\"\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o, c in freq.most_common(40000)] # 40k most common words\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, { v: k for k, v in enumerate(itos) }) #reverse\n",
    "    ids = np.array([ ([stoi[o] for o in p] + [2]) for p in tok ])\n",
    "    np.save(TMP_PATH / f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH / f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids, en_itos, en_stoi = toks2ids(en_tok, 'en')\n",
    "fr_ids, fr_itos, fr_stoi = toks2ids(fr_tok, 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH / f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH / f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, { v: k for k, v in enumerate(itos) })\n",
    "    return ids, itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids, en_itos, en_stoi = load_ids('en')\n",
    "fr_ids, fr_itos, fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['qu’', 'est', '-ce', 'que', 'la', 'lumière', '?', '_eos_'], 17573, 24793)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook's fasttext word vectors available from https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download word vectors:\n",
    "\n",
    "We are using the pre-trained word vectors for English language, trained on Wikipedia using fastText. These vectors in dimension 300 were obtained using the skip-gram model: https://fasttext.cc/docs/en/pretrained-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Download Progress Summary as of Mon Jul  2 14:55:13 2018 ***              \n",
      "===============================================================================\n",
      "[#fe81f7 2.9GiB/9.6GiB(30%) CN:5 DL:55MiB ETA:2m5s]\n",
      "FILE: data/translate/wiki.en.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 14:56:14 2018 ***              \n",
      "===============================================================================\n",
      "[#fe81f7 5.8GiB/9.6GiB(60%) CN:5 DL:52MiB ETA:1m14s]\n",
      "FILE: data/translate/wiki.en.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 14:57:14 2018 ***              \n",
      "===============================================================================\n",
      "[#fe81f7 8.6GiB/9.6GiB(89%) CN:5 DL:52MiB ETA:19s]\n",
      "FILE: data/translate/wiki.en.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#fe81f7 9.6GiB/9.6GiB(99%) CN:2 DL:\u001b[32m39MiB\u001b[0m]\u001b[0m                        \n",
      "07/02 14:57:39 [\u001b[1;32mNOTICE\u001b[0m] Download complete: data/translate/wiki.en.zip\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "fe81f7|\u001b[1;32mOK\u001b[0m  |    47MiB/s|data/translate/wiki.en.zip\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "!aria2c --file-allocation=none -c -x 5 -s 5 -d data/translate https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.en.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *** Download Progress Summary as of Mon Jul  2 15:01:29 2018 ***              \n",
      "===============================================================================\n",
      "[#2e6d55 2.5GiB/5.5GiB(45%) CN:5 DL:34MiB ETA:1m29s]\n",
      "FILE: data/translate/wiki.fr.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " *** Download Progress Summary as of Mon Jul  2 15:02:29 2018 ***              \n",
      "===============================================================================\n",
      "[#2e6d55 5.3GiB/5.5GiB(95%) CN:5 DL:42MiB ETA:5s]\n",
      "FILE: data/translate/wiki.fr.zip\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "[#2e6d55 5.5GiB/5.5GiB(99%) CN:1 DL:\u001b[32m11MiB\u001b[0m]\u001b[0m                        \n",
      "07/02 15:02:47 [\u001b[1;32mNOTICE\u001b[0m] Download complete: data/translate/wiki.fr.zip\n",
      "\n",
      "Download Results:\n",
      "gid   |stat|avg speed  |path/URI\n",
      "======+====+===========+=======================================================\n",
      "2e6d55|\u001b[1;32mOK\u001b[0m  |    41MiB/s|data/translate/wiki.fr.zip\n",
      "\n",
      "Status Legend:\n",
      "(OK):download completed.\n"
     ]
    }
   ],
   "source": [
    "!aria2c --file-allocation=none -c -x 5 -s 5 -d data/translate https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.en.zip\n",
      "  inflating: data/translate/wiki.en.vec  \n",
      "  inflating: data/translate/wiki.en.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.en.zip -d data/translate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/translate/wiki.fr.zip\n",
      "  inflating: data/translate/wiki.fr.vec  \n",
      "  inflating: data/translate/wiki.fr.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip data/translate/wiki.fr.zip -d data/translate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the fastText library, you'll need to download [fasttext word vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) for your language (download the 'bin plus text' ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/fastText.git\n",
      "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-9tychtgg-build\n",
      "Collecting pybind11>=2.2 (from fasttext==0.8.22)\n",
      "  Downloading https://files.pythonhosted.org/packages/12/90/0f92a575dc60c8fba6d0c91d6b45abdb1058da9ebed40400cbcfad2ac0a7/pybind11-2.2.3-py2.py3-none-any.whl (144kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 1.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=0.7.0 in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/fastai/lib/python3.6/site-packages (from fasttext==0.8.22)\n",
      "Installing collected packages: pybind11, fasttext\n",
      "  Running setup.py install for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fasttext-0.8.22 pybind11-2.2.3\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH / 'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str((PATH / 'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    \"\"\"\n",
    "    get_word_vector:\n",
    "        [method] get the vector representation of word.\n",
    "    get_words:\n",
    "        [method] get the entire list of words of the dictionary optionally\n",
    "        including the frequency of the individual words. This\n",
    "        does not include any subwords. \n",
    "    \"\"\"\n",
    "    vecd = { w: ft_vecs.get_word_vector(w) for w in ft_vecs.get_words() }\n",
    "    pickle.dump(vecd, open(PATH / f'wiki.{lang}.pkl', 'wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH / 'wiki.en.pkl', 'rb'))\n",
    "fr_vecd = pickle.load(open(PATH / 'wiki.fr.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "ft_vecs = en_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2519370"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG\n",
    "ft_words = ft_vecs.get_words(include_freq=True)\n",
    "ft_word_dict = { k: v for k, v in zip(*ft_words) }\n",
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec, dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en_vecd type is dict\n",
    "en_vecs = np.stack(list(en_vecd.values())) # convert dict_values to list and then stack it\n",
    "en_vecs.mean(), en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exclude the extreme cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often corpuses have a pretty long tailed distribution of sequence length and it's the longest sequences that tend to overwhelm how long things take, how much memory is used, etc. So in this case, we are going to grab 99th to 97th percentile of the English and French and truncate them to that amount. Originally Jeremy was using 90 percentiles (hence the variable name):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 38)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 99))\n",
    "enlen_90, frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create our Dataset, DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x, self.y = x, y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return A(self.x[idx], self.y[idx]) # A for Arrays\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the training and testing set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an easy way to get training and validation sets. Grab a bunch of random numbers — one for each row of your data, and see if they are bigger than 0.1 or not. That gets you a list of booleans. Index into your array with that list of booleans to grab a training set, index into that array with the opposite of that list of booleans to get your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr)) > 0.1\n",
    "en_trn, fr_trn = en_ids_tr[trn_keep], fr_ids_tr[trn_keep] # training set\n",
    "en_val, fr_val = en_ids_tr[~trn_keep], fr_ids_tr[~trn_keep] # validation set\n",
    "len(en_trn), len(en_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create training and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn, en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val, en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "bs = 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of our preprocessing is complete, so making `numworkers = 1` will save you some time.\n",
    "- Padding will pad the shorter phrases to be the same length.\n",
    "- Classifier → padding in the beginning.\n",
    "- Decoder → padding at the end.\n",
    "- Sampler - so we keep the similar sentences together (sorted by length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arranges sentences so that similar lengths are close to each other\n",
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create DataLoaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1,\n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs * 1.6), transpose=True, transpose_y=True, num_workers=1,\n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38, 29), (21, 7), (21, 8), (38, 13), (38, 21)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test - inspect\n",
    "\n",
    "it = iter(trn_dl) # trn_dl is iterable. turns iterable into iterator.\n",
    "# Return the next item from the iterator.\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x), len(y)) for x, y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture diagram](https://s15.postimg.cc/x710hbkdn/1_1f_KDa_Dsww_Vu3w2_Zt_Cg-_Uow.png)\n",
    "\n",
    "- The architecture is going to take our sequence of tokens.\n",
    "- It is going to spit them into an encoder (a.k.a. backbone).\n",
    "- That is going to spit out the final hidden state which for each sentence, it’s just a single vector.\n",
    "- Then, it will need to be passed to a decoder that will walk through the words one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    \"\"\"\n",
    "    Creates embedding:\n",
    "    1. rows = number of vocab\n",
    "    2. cols = embedding size dimension\n",
    "    \n",
    "    Will randomly initialize the embedding\n",
    "    \"\"\"\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    \n",
    "    # goes through the embedding and replace\n",
    "    # the initialized weights with existing word vectors\n",
    "    # multiply x3 to compensate for the stdev 0.3\n",
    "    for i, w in enumerate(itos):\n",
    "        try:\n",
    "            wgts[i] = torch.from_numpy(vecs[w] * 3)\n",
    "        except:\n",
    "            miss.append(w)\n",
    "    print(len(miss), miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh, nl = 256, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder (enc)\n",
    "        self.nl, self.nh, self.out_sl = nl, nh, out_sl\n",
    "        \n",
    "        # for each word, pull up the 300M vector and create an embedding\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        \n",
    "        # GRU - similiar to LSTM\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        # decoder (dec)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl, bs = inp.size()\n",
    "\n",
    "        # ==================================================\n",
    "        # Encoder version\n",
    "        # ==================================================\n",
    "        \n",
    "        # initialize the hidden layer\n",
    "        h = self.initHidden(bs)\n",
    "        \n",
    "        # run the input through our embeddings + apply dropout\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        \n",
    "        # run it through the RNN layer\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        \n",
    "        # run the hidden state through our linear layer\n",
    "        h = self.out_enc(h)\n",
    "        \n",
    "        # ==================================================\n",
    "        # Decoder version\n",
    "        # ==================================================\n",
    "        \n",
    "        # starting with a 0 (or beginning of string _BOS_)\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        \n",
    "        # will loop as long as the longest english sentence\n",
    "        for i in range(self.out_sl):\n",
    "            \n",
    "            # embedding - we are only looking at a section at time\n",
    "            # which is why the .unsqueeze is required\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            \n",
    "            # rnn - typically works with whole phrases, but we passing\n",
    "            # only 1 unit at a time in a loop\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            \n",
    "            # dropout\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            \n",
    "            res.append(outp)\n",
    "            \n",
    "            # highest probability word\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            \n",
    "            # if its padding ,we are at the end of the sentence\n",
    "            if (dec_inp == 1).all():\n",
    "                break\n",
    "\n",
    "        # stack the output into a single tensor\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs):\n",
    "        return V(torch.zeros(self.nl, bs, self.nh))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    \"\"\"\n",
    "    Loss function - modified version of cross entropy\n",
    "    \"\"\"\n",
    "    sl, bs = target.size()\n",
    "    sl_in, bs_in, nc = input.size()\n",
    "    \n",
    "    # sequence length could be shorter than the original\n",
    "    # need to add padding to even out the size\n",
    "    if sl > sl_in:\n",
    "        input = F.pad(input, (0, 0, 0, 0, 0, sl - sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1, nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e45ba3d891a43c8bc1cb451c9afa881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 235/362 [01:11<00:38,  3.28it/s, loss=29.5]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEOCAYAAACaQSCZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8VFX6+PHPkw5ptACphNB7MSAoIoiCYsEGyFqwomtZt7m6+v1tcb+2dXW/u6urorKWtQtYAEFkUUBpoffekhAIPbSQhOf3xwwa2QlMkrlzJ8nzfr3mlXvP3Dv3mcMwz5xz7r1HVBVjjDHmbMLcDsAYY0zNYAnDGGOMXyxhGGOM8YslDGOMMX6xhGGMMcYvljCMMcb4xbGEISLpIjJTRNaIyCoRedBb/gcRyRORpd7H0Ar2v1RE1onIRhF5xKk4jTHG+Eecug5DRJKBZFVdLCLxwCLgamAEcFhV/3KGfcOB9cAlQC6wEBilqqsdCdYYY8xZOdbCUNWdqrrYu1wErAFS/dy9N7BRVTer6gngfWCYM5EaY4zxR1DGMEQkE+gBzPcW3S8iy0VknIg09LFLKrCj3HouFSQbERkjIjnex5gAhm2MMaYcx7qkvj+ASBzwDfCEqk4QkWbAHkCBP+Hptrr9tH2GA0NU9U7v+s1Ab1V94EzHatKkiWZmZjrwLowxpnZatGjRHlVN8mfbCCcDEZFIYDzwjqpOAFDVXeWefxWY5GPXXCC93HoakH+242VmZpKTk1OtmI0xpi4RkW3+buvkWVICvA6sUdXny5Unl9vsGmClj90XAm1EpKWIRAE3AJ85Fasxxpizc7KFcT5wM7BCRJZ6yx4FRolIdzxdUluBuwFEJAV4TVWHqmqpiNwPTAPCgXGqusrBWI0xxpyFYwlDVecA4uOpKRVsnw8MLbc+paJtjTHGBJ9d6W2MMcYvljCMMcb4xRKGMcYYv1jCMMaYGmxtwSEWbdsXlGNZwjDGmBrs2anruOutRRwvKXP8WJYwjDGmhlpXUMSMtbsZ3TeTmMhwx49nCcMYY2qoV2Ztol5kOLf0bRGU41nCMMaYGuhwcSmfL8tnRHYaDWOjgnJMSxjGGFMDzdu0l5IyZUjn5kE7piUMY4ypgeZs3ENMZBg9M3zNEOEMSxjGGFMDfbtxD70yGwVlsPsUSxjGGFPD7Dp0nA27D9OvdZOgHtcShjHG1CC7Dx3nsYmeWSH6tQluwnB0AiVjjDGBo6rc+q+FbCw8zMOXtqdTSmJQj28Jwxhjaoj5W/axeuchnrmuCyN7ZQT9+NYlZYwxNcTbc7eRWC+Sq7qlunJ8SxjGGFMD5B04xrRVBQw/J416UcE7M6o8SxjGGFMDPDllDeFhwq3nZ7oWgyUMY4wJcd9t2sPk5Tu5d0Br0hrWdy0OSxjGGBPixs7aTPOEGO6+MMvVOCxhGGNMCNt7uJjZG/ZwdY/UoF7V7YtjCUNE0kVkpoisEZFVIvKgt/xZEVkrIstFZKKINKhg/60iskJElopIjlNxGmNMKJuyYidlJ5Vh3VPcDsXRFkYp8CtV7QD0Ae4TkY7AdKCzqnYF1gO/PcNrDFTV7qqa7WCcxhgTsj5Zmk/bZnG0bx7vdijOJQxV3amqi73LRcAaIFVVv1TVUu9m84A0p2Iwxpia7PNl+Szatp8R2emIiNvhBGcMQ0QygR7A/NOeuh34ooLdFPhSRBaJyJgzvPYYEckRkZzCwsJAhGuMMa4rOHicxyauoHt6A0afl+l2OEAQEoaIxAHjgZ+r6qFy5Y/h6bZ6p4Jdz1fVnsBleLqz+vvaSFXHqmq2qmYnJSUFOHpjjHHHuwu2U1RcyvMjuhEZHhrnJzkahYhE4kkW76jqhHLlo4ErgBtVVX3tq6r53r+7gYlAbydjNcaYUDJtZQG9MhuRlRTndijfc/IsKQFeB9ao6vPlyi8FHgauUtWjFewbKyLxp5aBwcBKp2I1xphQsrnwMOt2FXFpp+BNv+oPJ1sY5wM3Axd5T41dKiJDgReAeGC6t+xlABFJEZEp3n2bAXNEZBmwAJisqlMdjNUYY0LG1FUFAFwaxPm6/eHY7c1VdQ7ga1h/io+yU11QQ73Lm4FuTsVmjDGh6NiJMh6ftIrxi/LokdGAlAb13A7pR2w+DGOMCQEnTyo//2AJX67exU3ntuDega3cDum/WMIwxpgQ8NI3m5i2ahe/u6Ijt/dr6XY4PoXGuVrGGFOH7T9ygpe+3sTgjs24zcXbl5+NJQxjjHHZP7/eyJETpTw0pF1IXNFdEeuSMsYYlxQWFfPrj5bxzfpCruuZRptm7t8v6kwsYRhjjEuen76OuZv28shl7bk1RG7/cSaWMIwxxgW5+4/y8aJcRvXO4J4LQ++MKF9sDMMYY1zw4syNADUmWYAlDGOMCbqcrft4f+EObu6TGXIX552JJQxjjAmi4tIyfjN+OSmJ9fjV4LZuh1MpNoZhjDFB9Ma3W9lceIQ3butFbHTN+gq2FoYxxgTJnsPFvPCfjVzUvikD2jV1O5xKs4RhjDFB8tLXmzhaUsajQzu4HUqVWMIwxpggOHS8hPcXbOfKrsm0bho6kyJVhiUMY4wJgg8W7ODIiTLu6JfldihVZgnDGGMctmjbPl7+ZhPntmxEl7REt8OpMksYxhjjoO827WHEK/OIjY7g8WGd3Q6nWmrWOV3GGFODqCrPfLGW5gkxTPpZPxJiIt0OqVqshWGMMQ6ZsWY3y3IP8rNBrWt8sgBLGMYY45h/zNxIi8b1ubZnmtuhBIRjCUNE0kVkpoisEZFVIvKgt7yRiEwXkQ3evw0r2H+0d5sNIjLaqTiNMcYJS7bvZ9mOA9zRryWR4bXjt7mT76IU+JWqdgD6APeJSEfgEWCGqrYBZnjXf0REGgG/B84FegO/ryixGGNMKHrju63ER0fUmtYFOJgwVHWnqi72LhcBa4BUYBjwpnezN4Grfew+BJiuqvtUdT8wHbjUqViNMSaQ1u8qYvLynQzPTieuht0v6kyC0k4SkUygBzAfaKaqO8GTVABfN1RJBXaUW8/1lvl67TEikiMiOYWFhYEM2xhjKu3gsRLGvJVDw9go7rmw5l6k54vjCUNE4oDxwM9V9ZC/u/koU18bqupYVc1W1eykpKSqhmmMMQHx1+nryd1/jH/e2JOmCTFuhxNQjiYMEYnEkyzeUdUJ3uJdIpLsfT4Z2O1j11wgvdx6GpDvZKzGGFNdR4pLGb8olyu6JtMrs5Hb4QSck2dJCfA6sEZVny/31GfAqbOeRgOf+th9GjBYRBp6B7sHe8uMMSZkTVySR1FxKTf3zXQ7FEc42cI4H7gZuEhElnofQ4GngUtEZANwiXcdEckWkdcAVHUf8CdgoffxuLfMGGNCkqry9txtdEpJoGdGA7fDcYRjw/eqOgffYxEAg3xsnwPcWW59HDDOmeiMMSawFmzZx7pdRTxzXRc8HSy1T+24msQYY1z21rxtJNaL5KpuPk/orBUsYRhjTDXtPnScaSsLGH5OGvWiwt0OxzGWMIwxppo+zNlB6Unlpj4t3A7FUZYwjDGmGk6eVD7MyaVvVmMym8S6HY6jLGEYY0w1zNu8l+37jnJD7/Szb1zDWcIwxphqeGf+dhLrRTKkU3O3Q3GcJQxjjKmi1fmHmLxiJzeem0FMZO0d7D7FEoYxxlTRc1+uIyEmgrv7t3I7lKCwhGGMMVWw8+AxZqzdzR39skisX/OnX/WHJQxjjKmCjbsPA9C7Ze27yWBFLGEYY0wVbNlzBIBWSbX7VNryLGEYY0wVbC48QmxUOEnx0W6HEjSWMIwxpgo27zlCy6TYWnujQV8sYRhjTBVs2XOYlk3i3A4jqCxhGGNMJR0vKSN3/zGyavmtQE5nCcMYYypp+76jqEJWHRrwBksYxhhTaZsLPWdItbQWhjHGmDNZkXcAoNbfnfZ0ljCMMaYSdh48xr++3crFHZqREFM3rvA+xRKGMcZUwpNT1lJ2Uvn9lR3dDiXoIpx6YREZB1wB7FbVzt6yD4B23k0aAAdUtbuPfbcCRUAZUKqq2U7FaYwx/jpcXMoXK3Yy+rxM0hvVdzucoHMsYQBvAC8Ab50qUNWRp5ZF5Dng4Bn2H6iqexyLzhhjKmn+5r2UnlQGtW/qdiiucCxhqOosEcn09Zx4Lo0cAVzk1PGNMSbQ5mzcQ3REGD1bNHQ7FFe4NYZxAbBLVTdU8LwCX4rIIhEZE8S4jDGmQt9u3EPvlo3qxGRJvjjZJXUmo4D3zvD8+aqaLyJNgekislZVZ/na0JtQxgBkZGQEPlJjjAF2HzrO+l2Hua5nmtuhuCboLQwRiQCuBT6oaBtVzff+3Q1MBHqfYduxqpqtqtlJSUmBDtcYYwD461frARhYR8cvwJ0uqYuBtaqa6+tJEYkVkfhTy8BgYGUQ4zPGmB/5ZEke7y3Ywb0DWtG2Wbzb4bjGsYQhIu8Bc4F2IpIrInd4n7qB07qjRCRFRKZ4V5sBc0RkGbAAmKyqU52K0xhjzmRT4WEenbiCXpkN+eUlbd0Ox1VOniU1qoLyW32U5QNDvcubgW5OxWWMMf4qKTvJfe8sJiYynL+P6kFEeN2+1rluv3s8H4gvVxWwMu9Ml4QYY+qiKSt2sragiCeu7kxyYj23w3FdnU8YJ1X51YfLePO7rW6HYowJIarKuDlbaNkkliGdmrsdTkio8wkjOiKcQR2aMn3NLkrLTrodjjEmRCzefoBluQe57fxMwsLqzjSsZ1LnEwbApZ2bc+BoCQu27HM7FGNMiBg3ZwsJMRF1+rqL01nCAC5s25SYyDC+WFngdijGmBCQu/8oX6zcyajeGcRGu3V9c+ixhAHUiwpnQNumTF1VQIl1SxlT5709dxsiwi3nZbodSkixhOE1PDuNwqJiplorw5g66eiJUnbsO8rUlQWM+3YLl3VuTmoDOzOqPGtreQ1s15TMxvX517dbuLJbitvhGGOC6ORJ5dZxC1mw1TOO2T29AU9c08XlqEKPJQyvsDBh9HmZ/PHz1SzZvp8eGXXz9sXG1EXvzN/Ggq37uP38liQnxnBD73Ti69j0q/7wq0tKRB4UkQTxeF1EFovIYKeDC7bh2ek0rB/J89PXux2KMSZIDhw9wTNT13FBmyb8vys6cFf/LEsWFfB3DON2VT2E50aAScBtwNOOReWSuOgI7hvYmtkb9jBng032Z0xd8MHCHRwuLuWxyzvgmdvNVMTfhHGqFocC/1LVZeXKapWb+7YgtUE9npu+zu1QjDEOKy07yVtzt9EnqxHtmye4HU7I8zdhLBKRL/EkjGne24/XyvNPoyPCGdM/iyXbD7Bom13IZ0xtNmPtbvIOHOPW81q6HUqN4G/CuAN4BOilqkeBSDzdUrXS8Ow0EutF8uqsLW6HYoxx0NxNe6kXGc7FHerupEiV4W/C6AusU9UDInIT8D9Arb29a/2oCG48N4NpqwuYv3mv2+EYYxyyrqCIts3j6/xty/3lby29BBwVkW7Ab4BtwFuORRUC7r6wFS2bxHL3vxexdc8Rt8MxxgSYqrK24BDt6/AMepXlb8IoVVUFhgF/U9W/AbW6lhPrRfKvW3uhCr8ZvxzP2zfG1BaFRcXsP1pC++Ra/VUWUP4mjCIR+S1wMzBZRMLxjGPUai0ax/Lwpe1ZsGUfny3LdzscY0wArS0oAqBdc0sY/vI3YYwEivFcj1EApALPOhZVCBnZK53OqQn87+Q17C467nY4xpgAWedNGHY6rf/8ShjeJPEOkCgiVwDHVbVWj2GcEh4mPHt9N4qOl/DAu0tskiVjaok1BYdoGh9No9got0OpMfy9NcgIYAEwHBgBzBeR650MLJR0SE7gyWu6MH/LPh6buNLGM4ypBdYVFFl3VCX52yX1GJ5rMEar6i1Ab+D/nWkHERknIrtFZGW5sj+ISJ6ILPU+hlaw76Uisk5ENorII/6+GSdd2zONn13Umg9ydvDMVLsK3Jia7HhJGesKiuiUkuh2KDWKv3erDVPV3eXW93L2ZPMG8AL/ffrtX1X1LxXt5B1QfxG4BMgFForIZ6q62s9YHfOLS9qy98gJXv5mE41iIxnTv5XbIRljqmD1zkOUnlS6pzdwO5Qaxd+EMVVEpgHveddHAlPOtIOqzhKRzCrE1BvYqKqbAUTkfTyn87qeMESEx4d15sCxEp6cspaG9aMYnp3udljGmEpauv0AgCWMSvJ30PshYCzQFegGjFXVh6t4zPtFZLm3y8rXpBOpwI5y67neMp9EZIyI5IhITmFhYRVD8l94mPD8iG70a92ERyasYMaaXY4f0xgTWMtyD9A8IYbmiTFuh1Kj+H09vKqOV9VfquovVHViFY/3EtAK6A7sBJ7zsY2vu+BWOMqsqmNVNVtVs5OSkqoYVuVER4Tzys3n0DE5gZ+9t+T70/OMMTXDsh0H6JZu4xeVdcaEISJFInLIx6NIRA5V9mCquktVy1T1JPAqnu6n0+UC5ft50oCQu2ouNjqCV2/JJjY6gpten8/MdbvPvpMxxnUHjp5g696jdLPuqEo7Y8JQ1XhVTfDxiFfVSl/tIiLJ5VavAVb62Gwh0EZEWopIFHAD8FlljxUMzRNjeOuO3jSsH8lt/1rIwx8v59DxErfDMsacwbcbPTcU7ZFu0zBXlmO3aBSR94C5QDsRyRWRO4A/i8gKEVkODAR+4d02RUSmAKhqKXA/MA1YA3yoqqucirO62jdP4PMH+nHvgFZ8tGgHQ/46i1nrnR9LMcZUzfsLt5OSGEPvlo3cDqXGkdp0EVp2drbm5OS4dvylOw7wqw+XsnnPEZ6+tgsje2W4Fosx5r/t2HeU/s/O5MFBbfj5xW3dDickiMgiVc32Z1u7CXwAdU9vwOSfXUD/Nkk8PH4FT01Zw8Gj1kVlTKj4KGcHAoyw0+GrxBJGgMVEes6gGn5OGmNnb6b/szMZO2sTx0vK3A7NmDpvbUERbZrGk9Kgntuh1EiWMBwQExnOs8O7MfmBC+iR0YAnp6zl4ue/YdLyfLsPlTEuOnishMT6tX5mBsdYwnBQx5QE3ritN+/ceS5x0RHc/+4SrnvpO6atKqDspCUOY4Lt4LESEmIsYVSVJYwgOL91Eyb/7AKevrYLuw4Vc/fbi7joua/517dbOFxc6nZ4xtQZRcdLSaxnCaOqLGEESXiYcEPvDL55aAAv/qQnjWOj+OPnq+n71AyemrKGXYdsciZjnHbwWIkljGrw9+aDJkAiwsO4vGsyl3dNZvH2/bw+Zwuvzt7M2/O2cf9FrbmjX0uiI8LdDtOYWqe07CSHi0tJqGdfe1VlLQwX9cxoyIs/6cnMXw+gX+sm/HnqOgb/dZbd0NAYBxw67un+tRZG1VnCCAEtGscy9pZs3rq9N+Fhwh1v5vCTV+cxffUuGxw3JkAOHfNcE2UJo+osYYSQ/m2TmPpgf/7n8g5sLjzCXW/l0P/PM3nj2y2cKLW5xI2pjoOWMKrNOvNCTFREGHdekMXo8zL5avUu/vXtVv7w+Wpem7OFa3qkcmW3FNo2s3mIjamsUwkjwRJGlVnCCFGR4WFc1iWZSzs35+t1hbw2ZzMvztzIP/6zkXbN4rmyWzJXdE0hs0ms26EaUyNYC6P6LGGEOBFhYPumDGzflMKiYr5YuZPPl+Xzly/X85cv19M1LZEru6Zweddku92BMWdwauoBSxhVZwmjBkmKj+aWvpnc0jeT/APHmLx8J58vz+eJKWt4YsoaemU25MpuKVzWOZmk+Gi3wzUmpHzfJWVXeleZJYwaKqVBPe7qn8Vd/bPYuucIk5bn8/mynfzu01X88fPVDGzXlJ+cm86FbZsSHuZr1ltj6paDx0qICg8jJtLO9akqSxi1QGaTWO6/qA33X9SGdQVFTFySx8eLdvDVml2kJMZwY58WjOqdQaPYKLdDNcY1h46VkFAvEhH7AVVVlmprmXbN43nksvZ898ggXrqxJy2TYnl22jr6PDWD33y8jFX5B90O0RhXHDpWSqJd5V0tVnu1VFSE5yyry7oks66giDfnbmXi4jw+zMmld2YjRp+XyZBOzYgIt98Mpm446G1hmKqzhFEHtGsez5PXdOHhIe35aNEO3py7lfveXUzzhBhu6J3OqN4ZNEuIcTtMYxx18FgJjeOsW7Y6LGHUIYn1I7nzgixuO78l/1m7m7fnbeP/vtrAP/6zkcEdm3FTnxac16qx9fGaWunQ8RKykuy6pepwLGGIyDjgCmC3qnb2lj0LXAmcADYBt6nqAR/7bgWKgDKg1N8Jyo1/wsOESzo245KOzdi65wjvLtjORzk7+GJlAVlNYhnVO4NreqbSJM5OzTW1h02eVH1OdmC/AVx6Wtl0oLOqdgXWA789w/4DVbW7JQtnZTaJ5dGhHZj720E8P6IbDWOjeGLKGvo8OYOf/nsRM9ftthsgmhrv5EnlkM2FUW2OtTBUdZaIZJ5W9mW51XnA9U4d31ROTGQ41/ZM49qeaWzYVcQHC3cwYUkeX6wsIDkxhuHnpDE8O530RvXdDtWYSjtaUsZJhfgY64WvDjdPkbkd+KKC5xT4UkQWiciYM72IiIwRkRwRySksLAx4kHVRm2bx/M8VHZn320H888aetG0Wzz9mbuSCP8/kptfm88mSPA4cPeF2mMb4rbikDPD8MDJV50q6FZHHgFLgnQo2OV9V80WkKTBdRNaq6ixfG6rqWGAsQHZ2tvWdBFBURBhDuyQztEsyeQeO8XFOLh/m7ODnHywlPEw4J6MhV/dIZXh2GpF2eq4JYSfKPNMDREXY57Q6gl57IjIaz2D4jarq8wteVfO9f3cDE4HewYvQ+JLaoB4PXtyG2b8ZyIR7z+PeAa04dLyERyeuYNBz3/DJkjxO2liHCVHFJZ6EEW0Jo1qCWnsicinwMHCVqh6tYJtYEYk/tQwMBlYGL0pzJmFhQs+MhvxqcDu+ePACxt2aTWx0BD//YClD/z6br1bvooLfAca4xloYgeFY7YnIe8BcoJ2I5IrIHcALQDyebqalIvKyd9sUEZni3bUZMEdElgELgMmqOtWpOE3ViQgXtW/G5Af68bcbunO8pIw738rhupe+s+llTUj5oYVhYxjV4eRZUqN8FL9ewbb5wFDv8magm1NxmcALCxOGdU9laJdkPl6Uyz9mbOCut3Jo0bg+N53bgnOzGtG+eYL9ujOuOVHmGfS2z2D12DlmJmAiw8MY1TuD689JY9qqAsbN2cITU9YAEBUexrlZjfjlJW3pkdHQ5UhNXWNjGIFhCcMEXGR4GFd0TeGKrins2HeU5bkHWZZ7gAmLc7nmn9+R3aIhI3ulc3nXZOpH2UfQOK+4zBJGIFjtGUelN6rP5V2TeXRoB75+aCCPDm3PvqMneOjj5fR5cgYfLtxhg+TGcadaGNYlVT1WeyZo4qIjGNO/FTN+eSEf3dOX9skJ/Gb8ci7722w+WLid496Lq4wJtOJSz2fLBr2rxxKGCToRoVdmI96/qw9/Ge45v+Hh8Ss47+n/MHbWJkscJuBOlFqXVCBYB7JxTViYcP05aVzXM5V5m/fx0jebeHLKWl6cuYkruiZzbc80emY0sNutm2ortoQREJYwjOtEhL6tGtO3VWPmbtrL+wu3M35xLu/M305m4/pc1zONkb3TaRpvkzyZqjnVwrAxjOqxhGFCyqnEUXS8hKkrC5iwOI/npq/n7//ZwGWdk7m5bwuyWzS0VoeplB9aGDaGUR2WMExIio+JZHh2OsOz09lceJi3523j45xcPluWT5umcYzqncF1PdNIrG/zG5izsxZGYFjCMCEvKymO31/ZiYeGtGPSsp28s2A7j09azTNT1zKoQ1P6tmpC36xGtEqKs5aH8am4tIyIMCE8zD4f1WEJw9QY9aMiGNErnRG90lmVf5D3F+xg+updTFlRAECrpFhuPLcFgzo0pUVjm7vZ/OBE6Ukb8A4ASximRuqUksifrk7k8WGd2L7vKHM27uHDhTt4fNJqHp+0mo7JCYzslc6I7HTqRVm/dV1XXHrSuqMCwBKGqdFEhBaNY2nR2NO62Fx4mJnrCvl0aR6//2wVf5uxgVvPy2R030wb76jDikvLbMA7ACxhmFolKymOrKQ47ujXkoVb9/HS15t4fvp6XvlmEz85N4M7+mXRPNFOz61rTlgLIyAsYZhaq1dmI3rd2og1Ow/xyjebGPftVt78bhvX9kxlTP8sspLi3A7RBEmxjWEEhNWgqfU6JCfwfzf0YOavBjCyVzoTluQx6PlvuO+dxew+dNzt8EwQnCg9SXSkfd1Vl9WgqTMyGtfnT1d35tuHL+KnF7ZixtpdDP37HKauLLD5yGu54tKTRIXb1111WQ2aOicpPprfXNqeT+/rR4P6kdzz70UM/ftsPl+Wb9PK1lKe02pt0Lu6LGGYOqtd83imPngBfx3ZjdKTygPvLWHYi3NYuHWf26GZACsuLbNB7wCwGjR1WkR4GNf0SOPLn/fnbzd0Z+/hEwx/eS73v7uYjbuL3A7PBIgNegeGnSVlDJ5brQ/rnsolHZvxyjebeWXWJiav2MmQjs25d2AruqY1cDtEUw12Wm1gOFqDIjJORHaLyMpyZY1EZLqIbPD+bVjBvqO922wQkdFOxmnMKfWjIvjFJW359uGLuH9ga77btIerXviWm1+fz9xNe2062Rqq2MYwAsLplPsGcOlpZY8AM1S1DTDDu/4jItII+D1wLtAb+H1FicUYJzSOi+ZXg9vx7SMX8chl7Vmzs4hRr87j2pe+46vVuyxx1DDFdlptQDhag6o6Czh9BHEY8KZ3+U3gah+7DgGmq+o+Vd0PTOe/E48xjouPieSeC1sx5+GB/GlYJwqLirnzrRyufvFb5mzY43Z4xk/FpWV2Wm0AuFGDzVR1J4D3b1Mf26QCO8qt53rL/ouIjBGRHBHJKSwsDHiwxgDERIZzc99MZv56AM9c14XComJuen0+N742jxW5B90Oz5yFXbgXGKFag75uWu+zD0BVx6pqtqpmJyUlORyWqesiw8MY2SuDmQ8N4HdXdGTNziKufGEOD76/hHUFRdZVFYJU1dMlZS2ManPjLKldIpKsqjtFJBnY7WObXGBAufU04OsgxGaMX6Ijwrm9X0uuz07jlW828dpXXUjWAAAQyUlEQVTsLXy6NJ8mcdH0yWrEpZ2bc0nHZjbQGgJKyjxJPDrS/i2qy42E8RkwGnja+/dTH9tMA54sN9A9GPhtcMIzxn8JMZE8NKQ9o/tmMnPdbuZu2su3m/YyaflOGsVGcU2PVLqkJtI+OZ52zeJtRkAXFJeWAdgYRgA4mjBE5D08LYUmIpKL58ynp4EPReQOYDsw3LttNnCPqt6pqvtE5E/AQu9LPa6qdvmtCVlNE2IY2SuDkb0yKDupzN5QyPsLdvDmd1sp9d5uJCk+mn6tm9ApJYGWTWK/f1gScdap+bxtDKP6HE0YqjqqgqcG+dg2B7iz3Po4YJxDoRnjmPAwYUC7pgxo15RjJ8rIO3CUxdsPMHvDHmatL2Tikrzvt+2UksDovplc1T2FGOsycUTxqYRhF+5Vm13pbYyD6kWF07ppPK2bxjMiOx1V5cDRErbsPcLKvIO8M287vxm/nP+dvJqL2jdlRHY6fVs1tlZHAJ1KGHald/VZwjAmiESEhrFRNIyNomdGQ27u04L5W/bxUU4uM9bu4pOl+XROTeDu/q0Y2iWZ8DBLHNX1fZeUnYBQbZYwjHGRiNAnqzF9shpzvKSMiUvyeHXWZh54bwkvfb2JEdlpNIyNokH9KGKjwmmWEEN6o/puh12j2KB34FjCMCZExESGM6p3BiOz05m0YifPfLGWP3y++r+2S21Qj1ZN42jbNI7szIZc0CaJ2Gj7r1wRG/QOHPuUGRNiwsKEq7qlcHmXZPYfPcGBoyUcPHaCoyfK2Fx4hAVb97Ft7xHemreX1+ZsISoijP5tmjCkU3Mu7tCMhrFRbr+FkPL9GIa1MKrNEoYxISo8TGgSF02TuOjvyy5ok8To8zIBzy/nxdv3M21VAdNWFvDVGs81sHHRETSMjaRRfc9YSaeUBPpkNeacFg2pH1X3/sv/0MKwMYzqqnufHmNqiaiIsO/HP353RUdW5B1k9oY97DlczIGjJew7coJdh4qZvWEzL87cRHiY0Dopjk4pCbRrHk98TCSTV+RTcPA4nVMT6ZKaSNe0BnROTahVieXUGIadVlt9tedTYUwdJiJ0TWvgc6Knw8WlLNq2n5yt+1iZd5A5G/cwwXstSEpiDB1TEpi/eR+fLs0HICYyjKu6pXBzn0y6pCUG9X04wU6rDRxLGMbUcnHREVzYNokL2/5wc86Dx0rYe7iYjEb1ifD27e8+dJwVeQf5as0uPlmSz4c5uXRKSeCqbilc0S2F1Ab13HoL1WIX7gWOJQxj6qDEepEk1ov8UVnThBgGJcQwqEMzfju0AxMX5zFhSR5PfbGWp75YS3aLhlzVPYVh3VJJrB9ZwSuHHmthBI4lDGPMf0mIiWT0eZmMPi+TbXuPMGn5Tj5bms/vPl3FE5PXcHmXZG7onUGvzIYhf1V6ccmpMQwb9K4uSxjGmDNq0TiW+wa25r6BrVmZd5D3Fmzn06X5TFiSR6ukWG7olcF156TRKERP59116DgxkWEkxNjXXXVZG80Y47fOqYk8cU0XFjw2iD9f35XEepE8MWUNfZ+awUMfLWNlXujNPph/4DgpDeqFfEuoJrCUa4yptPpREYzITmdEdjprCw7x9txtTFicx0eLcumQnMDwc9IY2Ss9JK5AzztwjJTEmjlgH2qshWGMqZb2zRN44pouzHt0EH+8qhNREWE8Pmk1fZ+awbPT1rK76Lir8eUfOEZKgxhXY6gt3E//xphaIbHeDwPlS7bvZ+yszfzz6028OmsL1/ZM5a7+WbRKigtqTMWlZewuKialhp4SHGosYRhjAq5HRkNeuukctuw5wmuzN/PxolzeX7iDSzo2Y1TvdLIzG5EQ4/ypubsOFgNYwggQSxjGGMe0bBLLE9d04ReXtOWt77by1rxtTF+9C/BcZT64U3Pu6NfSsVu25x04BlBjLzoMNZYwjDGOaxIXzS8Ht+Pega1ZtG0/S7bvZ1X+If49bxtvfLeVrCaxDOncnKu7p9KueXzAjrvzoCdhWAsjMCxhGGOCJiYynPNbN+H81k0AyN1/lC9WFDBrQyFjZ23mpa830b55PFd1T+GqbimkNaxeyyPf28JITrRB70AIesIQkXbAB+WKsoDfqer/ldtmAPApsMVbNEFVHw9akMaYoEhrWJ+7+mdxV/8s9hwuZsqKnXy6NJ8/T13Hn6euo2l8NEXHSxnWPYXbzm9Jm6ZxhFVi2tq8A8dpEhdFjN3aPCCCnjBUdR3QHUBEwoE8YKKPTWer6hXBjM0Y454mcdHc0jeTW/pmsmPfUT5bls/mwiMAjF/sGTRvEhfF6L6ZXNMz1a/Wh+eUWuuOChS3u6QGAZtUdZvLcRhjQkh6o/rcN7D19+u/HtKW2Rv28MWKnTw3fT3PTV9PaoN6nJvViAvbJjGgXdP/upliYVExK/IO0jercbDDr7XcThg3AO9V8FxfEVkG5AO/VtVVvjYSkTHAGICMjAxHgjTGuCs5sd73V5Zv3H2YORsKmb9lHzPX7mbC4jyiI8K4pGMz+rdJYkin5kRGCA+8t5gjxaU/SjymekRV3TmwSBSeZNBJVXed9lwCcFJVD4vIUOBvqtrmbK+ZnZ2tOTk5zgRsjAk5ZSeVZbkHmLg4jykrdrL3yAlio8KpFxXBnsPFPD+iG9f2THM7zJAmIotUNduvbV1MGMOA+1R1sB/bbgWyVXXPmbazhGFM3aWqrMw7xOtzNnPwWAn3DWxNdmYjt8MKeZVJGG52SY2igu4oEWkO7FJVFZHeeO55tTeYwRljahYRoUtaIv93Qw+3Q6m1XEkYIlIfuAS4u1zZPQCq+jJwPfBTESkFjgE3qFtNIWOMMYBLCUNVjwKNTyt7udzyC8ALwY7LGGNMxez25sYYY/xiCcMYY4xfLGEYY4zxiyUMY4wxfrGEYYwxxi+WMIwxxvjFtSu9nSAihcAR4IxXhAdAInAwCPuebduKnq9M+ellp683weqzoudCtT59HdeJ/dyoT19lteUzGuj6rKj89LI2qproR3yey+lr0wPICcIxxgZj37NtW9HzlSk/vczHep2vT3/rLlTqszp1Gur16VadBuMzGuj6rET9+f3erEuqaj4P0r5n27ai5ytTfnpZdd5bVYV6fVb0XKjWZ3WOG+r16c9xnRCMz2ig67Oi8ip/RmtVlxSAiOSonzfSMmdn9RlYVp+BZ3UaPLWxhTHW7QBqGavPwLL6DDyr0yCpdS0MY4wxzqiNLQxjjDEOsIRhjDHGL5YwjDHG+MUShjHGGL/UqYQhIgNEZLaIvCwiA9yOpzYQkVgRWSQiV7gdS00nIh28n82PReSnbsdT04nI1SLyqoh8KiKD3Y6nNqgxCUNExonIbhFZeVr5pSKyTkQ2isgjZ3kZBQ4DMUCuU7HWBAGqT4CHgQ+dibLmCER9quoaVb0HGAHU6esKAlSfn6jqXcCtwEgHw60zasxptSLSH8+X/Vuq2tlbFg6sxzM/eC6wEBgFhANPnfYStwN7VPWkiDQDnlfVG4MVf6gJUH12xXMfnxg8dTspONGHnkDUp6ruFpGrgEeAF1T13WDFH2oCVZ/e/Z4D3lHVxUEKv9ZyZU7vqlDVWSKSeVpxb2Cjqm4GEJH3gWGq+hRwpi6S/UC0E3HWFIGoTxEZCMQCHYFjIjJFVU86GniICtTnU1U/Az4TkclAnU0YAfp8CvA08IUli8CoMQmjAqnAjnLrucC5FW0sItcCQ4AGwAvOhlYjVao+VfUxABG5FW/rzdHoap7Kfj4HANfi+TEzxdHIaqZK1SfwAHAxkCgirVX1ZSeDqwtqesIQH2UV9rGp6gRggnPh1HiVqs/vN1B9I/Ch1AqV/Xx+DXztVDC1QGXr8+/A350Lp+6pMYPeFcgF0sutpwH5LsVSG1h9BpbVZ2BZfbqspieMhUAbEWkpIlHADcBnLsdUk1l9BpbVZ2BZfbqsxiQMEXkPmAu0E5FcEblDVUuB+4FpwBrgQ1Vd5WacNYXVZ2BZfQaW1WdoqjGn1RpjjHFXjWlhGGOMcZclDGOMMX6xhGGMMcYvljCMMcb4xRKGMcYYv1jCMMYY4xdLGMY1InI4CMe4ys/btAfymANE5Lwq7NdDRF7zLt8qIiFxvzMRyTz9NuM+tkkSkanBism4wxKGqfG8t732SVU/U9WnHTjmme7DNgCodMIAHgX+UaWAXKaqhcBOETnf7ViMcyxhmJAgIg+JyEIRWS4ifyxX/ol3Rr9VIjKmXPlhEXlcROYDfUVkq4j8UUQWi8gKEWnv3e77X+oi8oaI/F1EvhORzSJyvbc8TET+6T3GJBGZcuq502L8WkSeFJFvgAdF5EoRmS8iS0TkKxFp5r0l9z3AL0RkqYhc4P31Pd77/hb6+lIVkXigq6ou8/FcCxGZ4a2bGSKS4S1vJSLzvK/5uK8Wm3hmRJwsIstEZKWIjPSW9/LWwzIRWSAi8d6WxGxvHS721UoSkXARebbcv9Xd5Z7+BKizc8zUCapqD3u48gAOe/8OBsbiuRtpGDAJ6O99rpH3bz1gJdDYu67AiHKvtRV4wLt8L/Cad/lWPJMRAbwBfOQ9Rkc8cysAXI/nduJhQHM886Vc7yPer4F/lltvyA93S7gTeM67/Afg1+W2exfo513OANb4eO2BwPhy6+Xj/hwY7V2+HfjEuzwJGOVdvudUfZ72utcBr5ZbTwSigM1AL29ZAp47V9cHYrxlbYAc73ImsNK7PAb4H+9yNJADtPSupwIr3P5c2cO5R02/vbmpHQZ7H0u863F4vrBmAT8TkWu85ene8r1AGTD+tNc5dev6RXjmlfDlE/XM27FaPDMvAvQDPvKWF4jIzDPE+kG55TTgAxFJxvMlvKWCfS4GOnrm8wEgQUTiVbWo3DbJQGEF+/ct937eBv5crvxq7/K7wF987LsC+IuIPANMUtXZItIF2KmqCwFU9RB4WiPACyLSHU/9tvXxeoOBruVaYIl4/k22ALuBlAreg6kFLGGYUCDAU6r6yo8KPRMKXQz0VdWjIvI1nulgAY6ratlpr1Ps/VtGxZ/t4nLLctpffxwpt/wPPFP9fuaN9Q8V7BOG5z0cO8PrHuOH93Y2ft8ATlXXi8g5wFDgKRH5Ek/Xka/X+AWwC+jmjfm4j20ET0tumo/nYvC8D1NL2RiGCQXTgNtFJA5ARFJFpCmeX6/7vcmiPdDHoePPAa7zjmU0wzNo7Y9EIM+7PLpceREQX279Szx3WQXA+wv+dGuA1hUc5zs8t/IGzxjBHO/yPDxdTpR7/kdEJAU4qqr/xtMC6QmsBVJEpJd3m3jvIH4inpbHSeBmPHNln24a8FMRifTu29bbMgFPi+SMZ1OZms0ShnGdqn6Jp0tlroisAD7G84U7FYgQkeXAn/B8QTphPJ7JeVYCrwDzgYN+7PcH4CMRmQ3sKVf+OXDNqUFv4GdAtneQeDWe8YYfUdW1eKYSjT/9Oe/+t3nr4WbgQW/5z4FfisgCPF1avmLuAiwQkaXAY8D/quoJYCTwDxFZBkzH0zr4JzBaRObh+fI/4uP1XgNWA4u9p9q+wg+tuYHAZB/7mFrCbm9uDCAicap6WEQaAwuA81W1IMgx/AIoUtXX/Ny+PnBMVVVEbsAzAD7M0SDPHM8sYJiq7ncrBuMsG8MwxmOSiDTAM3j9p2AnC6+XgOGV2P4cPIPUAhzAcwaVK0QkCc94jiWLWsxaGMYYY/xiYxjGGGP8YgnDGGOMXyxhGGOM8YslDGOMMX6xhGGMMcYv/x/D1MMwB8CmGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the learning rate\n",
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model (15-20 mins to train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa19dcfa8db64e78baf878c7ba7fdada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.209042   5.980303  \n",
      "    1      4.513244   4.566818                              \n",
      "    2      4.056711   4.515142                              \n",
      "    3      3.775803   4.026515                              \n",
      "    4      3.595237   3.857968                              \n",
      "    5      3.519258   3.773164                              \n",
      "    6      3.160189   3.705156                              \n",
      "    7      3.108818   3.66531                               \n",
      "    8      3.142783   3.613333                              \n",
      "    9      3.192778   3.680305                              \n",
      "    10     2.844773   3.637095                              \n",
      "    11     2.857365   3.5963                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.5963])]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
