{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein GAN in Pytorch using LSUN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_utils; importlib.reload(torch_utils)\n",
    "from torch_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the LSUN scene classification dataset bedroom category, unzip it, and convert it to JPG files (the scripts folder is here in the `dl2_2017` folder):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ~/lsun_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl 'http://lsun.cs.princeton.edu/htbin/download.cgi?tag=latest&category=bedroom&set=train' -o ~/lsun_data/bedroom_train_lmdb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ~/lsun_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip ~/lsun_data/bedroom_train_lmdb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that in the last month the GAN training problem has been solved! [This paper](https://arxiv.org/abs/1701.07875) shows a minor change to the loss function and constraining the weights allows a GAN to reliably learn following a consistent loss schedule.\n",
    "\n",
    "First, we, set up batch size, image size, and size of noise vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, sz, nz = 64, 64, 100 # nz is the size of the latent z vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own codes\n",
    "# Where to store samples and models\n",
    "experiment_path = 'wgan_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('mkdir {0}'.format(experiment_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix seed\n",
    "manual_seed = random.randint(1, 10000)\n",
    "print(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch has the handy [torch-vision](https://github.com/pytorch/vision) library which makes handling images fast and easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/cifar10'\n",
    "data = datasets.CIFAR10(root=PATH, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Scale(sz),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even parallel processing is handling automatically by torch-vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, bs, True, num_workers=8)\n",
    "n = len(dataloader)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our activation function will be `tanh`, so we need to do some processing to view the generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, fs=(6,6)):\n",
    "    plt.figure(figsize=fs)\n",
    "    plt.imshow(np.transpose((img / 2 + 0.5).clamp(0, 1).numpy(), (1, 2, 0)), interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN definitions are a little big for a notebook, so we import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcgan; importlib.reload(dcgan)\n",
    "from dcgan import DCGAN_D, DCGAN_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch uses `module.apply()` for picking an initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nc is input image channels = 3\n",
    "# ngf is number of generator filter = 64\n",
    "# ngpu is number of GPUs to use = 1\n",
    "# n_extra_layers is number of extra layers on gen and disc = 1\n",
    "netG = DCGAN_G(sz, nz, 3, 64, 1, 1).cuda()\n",
    "netG.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = DCGAN_D(sz, 3, 64, 1, 1).cuda()\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some shortcuts to create tensors and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training (my own codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_checkpoint = experiment_path + '/netG_epoch_1.pth'\n",
    "netD_checkpoint = experiment_path + '/netD_epoch_1.pth'\n",
    "\n",
    "# set path to netG_checkpoint (to continue training)\n",
    "netG_model = '' # netG_checkpoint\n",
    "netD_model = '' # netD_checkpoint\n",
    "\n",
    "if netG_model != '':\n",
    "    netG.load_state_dict(torch.load(netG_model))\n",
    "    print('continue training generator/actor')\n",
    "\n",
    "if netD_model != '':\n",
    "    netD.load_state_dict(torch.load(netD_model))\n",
    "    print('continue training discriminator/critic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import FloatTensor as FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Var(*params):\n",
    "    return Variable( FT(*params).cuda() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise(b): \n",
    "    return Variable( FT(b, nz, 1, 1).cuda().normal_(0, 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder\n",
    "input = Var(bs, 3, sz, nz)\n",
    "\n",
    "# Fixed noise used just for visualizing images when done\n",
    "fixed_noise = create_noise(bs)\n",
    "\n",
    "# The numbers 0 and -1\n",
    "one = torch.FloatTensor([1]).cuda()\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimizer needs to be told what variables to optimize. A module automatically keeps track of its variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-4)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One forward step and one backward step for D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_D(v, init_grad):\n",
    "    err = netD(v)\n",
    "    err.backward(init_grad)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    for p in net.parameters(): # reset requires_grad\n",
    "        p.requires_grad = val # they are set to False below in netG update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(niter, first=True):\n",
    "    \n",
    "    gen_iterations = 0\n",
    "    \n",
    "    for epoch in range(niter):\n",
    "        data_iter = iter(dataloader)\n",
    "        i = 0\n",
    "        \n",
    "        while i < n:\n",
    "            ###########################\n",
    "            # (1) Update D network\n",
    "            ###########################\n",
    "            make_trainable(netD, True)\n",
    "            \n",
    "            # train the discriminator d_iters times\n",
    "            d_iters = (100 if first and (gen_iterations < 25) or gen_iterations % 500 == 0 \n",
    "                       else 5) # 5 is number of D iters per each G iter\n",
    "\n",
    "            j = 0\n",
    "            \n",
    "            while j < d_iters and i < n:\n",
    "                j += 1\n",
    "                i += 1\n",
    "                \n",
    "                # clamp parameters to a cube\n",
    "                for p in netD.parameters():\n",
    "                    p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "                # my own codes\n",
    "                data = next(data_iter)\n",
    "                \n",
    "                # train with real\n",
    "                real_cpu, _ = data # my own codes\n",
    "                real_cpu = real_cpu.cuda() # my own codes\n",
    "                real = Variable( data[0].cuda() )\n",
    "                netD.zero_grad()\n",
    "                errD_real = step_D(real, one)\n",
    "\n",
    "                # train with fake\n",
    "                fake = netG( create_noise(real.size()[0]) )\n",
    "                input.data.resize_(real.size()).copy_(fake.data)\n",
    "                errD_fake = step_D(input, mone)\n",
    "                errD = errD_real - errD_fake\n",
    "                optimizerD.step()\n",
    "\n",
    "            ###########################\n",
    "            # (2) Update G network\n",
    "            ###########################\n",
    "            make_trainable(netD, False)\n",
    "            netG.zero_grad()\n",
    "            errG = step_D(netG(create_noise(bs)), one)\n",
    "            optimizerG.step()\n",
    "            gen_iterations += 1\n",
    "            \n",
    "            print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "                % (epoch, niter, i, n, gen_iterations,\n",
    "                errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "\n",
    "            if gen_iterations % 8 == 0: # every 500 generator iterations\n",
    "                print('saving real and fake images...')\n",
    "                real_cpu = real_cpu.mul(0.5).add(0.5)\n",
    "                vutils.save_image(real_cpu, '{0}/real_samples.png'.format(experiment_path))\n",
    "                fake = netG(create_noise(bs)) # create_noise replaced these codes: Variable(fixed_noise, volatile=True)\n",
    "                fake.data = fake.data.mul(0.5).add(0.5)\n",
    "                vutils.save_image(fake.data, '{0}/fake_samples_{1}.png'.format(experiment_path, gen_iterations))\n",
    "          \n",
    "        # do checkpointing\n",
    "        torch.save(netG.state_dict(), '{0}/netG_epoch_{1}.pth'.format(experiment_path, epoch))\n",
    "        torch.save(netD.state_dict(), '{0}/netD_epoch_{1}.pth'.format(experiment_path, epoch))\n",
    "        \n",
    "#         print('[%d/%d][%d/%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f' % (\n",
    "#             epoch, niter, gen_iterations, n,\n",
    "#             errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time train(200, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = netG(fixed_noise).data.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated images by Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(vutils.make_grid(fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real images from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(vutils.make_grid(iter(dataloader).next()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
